

# Papers Found on: 2026-02-19

### Illustration of Barren Plateaus in Quantum Computing
* **Authors:** Gerhard Stenzel et al.
* **Published (v1):** 2026-02-18
* **Updated:** 2026-02-18
* **Link:** http://arxiv.org/abs/2602.16558v1
* **Abstract:** Variational Quantum Circuits (VQCs) have emerged as a promising paradigm for quantum machine learning in the NISQ era. While parameter sharing in VQCs can reduce the parameter space dimensionality and potentially mitigate the barren plateau phenomenon, it introduces a complex trade-off that has been largely overlooked. This paper investigates how parameter sharing, despite creating better global optima with fewer parameters, fundamentally alters the optimization landscape through deceptive gradients -- regions where gradient information exists but systematically misleads optimizers away from global optima. Through systematic experimental analysis, we demonstrate that increasing degrees of parameter sharing generate more complex solution landscapes with heightened gradient magnitudes and measurably higher deceptiveness ratios. Our findings reveal that traditional gradient-based optimizers (Adam, SGD) show progressively degraded convergence as parameter sharing increases, with performance heavily dependent on hyperparameter selection. We introduce a novel gradient deceptiveness detection algorithm and a quantitative framework for measuring optimization difficulty in quantum circuits, establishing that while parameter sharing can improve circuit expressivity by orders of magnitude, this comes at the cost of significantly increased landscape deceptiveness. These insights provide important considerations for quantum circuit design in practical applications, highlighting the fundamental mismatch between classical optimization strategies and quantum parameter landscapes shaped by parameter sharing.

### MerLean: An Agentic Framework for Autoformalization in Quantum Computation
* **Authors:** Yuanjie Ren et al.
* **Published (v1):** 2026-02-18
* **Updated:** 2026-02-18
* **Link:** http://arxiv.org/abs/2602.16554v1
* **Abstract:** We introduce MerLean, a fully automated agentic framework for autoformalization in quantum computation. MerLean extracts mathematical statements from \LaTeX{} source files, formalizes them into verified Lean~4 code built on Mathlib, and translates the result back into human-readable \LaTeX{} for semantic review. We evaluate MerLean on three theoretical quantum computing papers producing 2,050 Lean declarations from 114 statements in total. MerLean achieves end-to-end formalization on all three papers, reducing the verification burden to only the newly introduced definitions and axioms. Our results demonstrate that agentic autoformalization can scale to frontier research, offering both a practical tool for machine-verified peer review and a scalable engine for mining high-quality synthetic data to train future reasoning models. Our approach can also be generalized to any other rigorous research in mathematics and theoretical physics.

### Computation of thermal conductivity based on Path Integral Monte Carlo methods
* **Authors:** Vladislav Efremkin et al.
* **Published (v1):** 2026-02-18
* **Updated:** 2026-02-18
* **Link:** http://arxiv.org/abs/2602.16405v1
* **Abstract:** The calculation of thermal conductivity in insulating solids at temperatures below the Debye temperature is problematic, due to the breakdown of classical and semi-classical approaches. In this work, we present a fully quantum methodology to compute thermal conductivity based on Path Integral Monte Carlo (PIMC) simulations combined with the Green-Kubo linear response theory. The method is applied to crystalline argon modeled by a Lennard-Jones potential, a paradigmatic system where quantum effects strongly affect both thermodynamic and transport properties. From PIMC simulations, we obtain the temperature-dependent phonon frequencies, lifetimes, and specific heat. From the imaginary time correlations of the energy current, we extract the thermal transport coefficients based on a physically motivated prior. We show that the experimentally observed increase of the thermal conductivity at low temperatures cannot be explained within a standard Peierls-Boltzmann framework or quasi-harmonic approximation using phonon lifetimes alone. Instead, a distinct transport lifetime emerges from the analysis of heat-current correlations. Our results demonstrate that quantum Monte Carlo methods provide a robust, non-perturbative framework to investigate heat transport in insulating solids, beyond the limits of classical molecular dynamics and quasi-harmonic approximations.

### Why the Casimir Force for Magnetic Metals Computed by the Lifshitz Theory Using the Drude Model Disagrees with the Measurement Data
* **Authors:** G. L. Klimchitskaya et al.
* **Published (v1):** 2026-02-18
* **Updated:** 2026-02-18
* **Link:** http://arxiv.org/abs/2602.16370v1
* **Abstract:** We consider the Casimir force in configurations with magnetic metal plates and analyze the reasons why the predictions of the Lifshitz theory using the dielectric permittivity of the Drude model are inconsistent with the measurement data. For this purpose, the contributions of the electromagnetic waves with the transverse magnetic and transverse electric polarizations to the Casimir force are computed using the Lifshitz theory expressed in terms of the pure imaginary Matsubara frequencies. Furthermore, the fractions of the evanescent and propagating waves in these contributions are found using an equivalent formulation of the Lifshitz theory along the real frequency axis. All computations are performed for Au-Ni and Ni-Ni plates using the Drude model and the experimentally consistent plasma model over the separation region from 0.5 to 6~mum, where the total force value is determined by conduction electrons. It is shown that the transverse magnetic contribution to the Casimir force does not depend on the used model of the dielectric permittivity, so that the total difference between the predictions of the Lifshitz theory using the Drude model and the measurement data is determined by the transverse electric contribution. In doing so, as opposed to the case of nonmagnetic metals, both fractions of the evanescent and propagating waves in this contribution depend on the model of the dielectric permittivity used in computations, whereas the magnetic properties of the plate metal influence the Casimir force solely through the fraction of propagating waves in the transverse electric contribution. The issue of a more adequate theoretical description of the electromagnetic response of magnetic metals is discussed.

### Magnetic resonance in quantum computing and in accurate measurements of the nuclear moments of atoms and molecules
* **Authors:** Zhichen Liu et al.
* **Published (v1):** 2026-02-11
* **Updated:** 2026-02-17
* **Link:** http://arxiv.org/abs/2602.11233v2
* **Abstract:** Modern experimental techniques can generate magnetic fields of the form H(t) = H0 z-hat + H1 [x-hat cos(ωt) + y-hat sin(ωt)], at frequencies within an order of magnitude of the nuclear magnetic resonance (NMR) and electron paramagnetic resonance (EPR) frequencies, ωn0 and ωe0, respectively, when acting on atoms or molecules. We derive simple closed-form expressions for the exact nuclear- and electronic-spin wave functions that enable controlled transitions between entangled states, allowing an atom or molecule to function as a quantum computer. These solutions also enable precise NMR or EPR measurements of nuclear moments in atoms and molecules. We present examples relevant to measurements of the nuclear moments of 14N, 7Li, and 133Cs. Because existing hyperfine measurements of the lowest three nuclear moments of 133Cs are mutually inconsistent, the proposed NMR/EPR experiments provide a route to measuring all seven of its nuclear moments with high precision.

### Drone delivery packing problem on a neutral-atom quantum computer
* **Authors:** Sara Tarquini et al.
* **Published (v1):** 2026-02-17
* **Updated:** 2026-02-17
* **Link:** http://arxiv.org/abs/2602.15487v1
* **Abstract:** Quantum architectures based on neutral atoms have gained significant attention in recent years as specialized computational machines due to their ability to directly encode the independent set constraint on graphs, exploiting the Rydberg blockade mechanism. In this work, we address the Drone Delivery Packing Problem via a hybrid quantum-classical framework leveraging a neutral-atom quantum processing unit (QPU). We reformulate the optimization task as a graph-partitioning problem based on the independent sets (ISs) of a scheduling graph that encodes delivery incompatibilities. Each partition corresponds to deliveries assigned to a single drone, with the objective of minimizing the total number of partitions. While the ISs represent time-feasible schedules, battery-duration constraints are enforced through a classical post-processing routine. This methodology enables the recovery of optimal delivery schedules, provided a sufficient number of samples is collected from the QPU to resolve the solution space. We benchmark the hybrid workflow through numerical emulations and demonstrate its effectiveness on Pasqal's Fresnel QPU, reporting hardware experiments with configurations of up to 100 atoms.

### Quantum Computing for Healthcare Digital Twin Systems
* **Authors:** Asma Taheri Monfared et al.
* **Published (v1):** 2026-02-17
* **Updated:** 2026-02-17
* **Link:** http://arxiv.org/abs/2602.15477v1
* **Abstract:** The growing complexity of healthcare systems requires advanced computational models for real-time monitoring, secure data exchange, and intelligent decision-making. Digital Twins (DTs) provide virtual representations of physical healthcare entities, enabling continuous patient monitoring and personalized care. However, classical DT frameworks face limitations in scalability, computational efficiency, and security. Recent studies have introduced Quantum Digital Twins (QDTs) to enhance performance through quantum computing, addressing challenges such as quantum-resistant security and efficient task offloading in healthcare environments. Despite these advances, most existing QDT models remain constrained by fundamental challenges related to quantum hardware limitations, hybrid classical-quantum system integration, cloud-based quantum access, scalability, and clinical trust. This paper provides a comprehensive review of QDTs for healthcare, with a particular focus on identifying and analyzing the key challenges that currently hinder their real-world adoption. Furthermore, it outlines critical research directions and enabling strategies aimed at advancing the development of secure, reliable, and clinically viable quantum digital twin systems for next-generation healthcare applications.

### Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit
* **Authors:** J. J. Prieto-Garcia et al.
* **Published (v1):** 2026-02-17
* **Updated:** 2026-02-17
* **Link:** http://arxiv.org/abs/2602.15474v1
* **Abstract:** We analyze numerically the performance of Quantum Reservoir Computing (QRC) for statistical and financial problems. We use a reservoir composed of two superconducting islands coupled via their charge degrees of freedom. The key non-linear elements that provide the reservoir with rich and complex dynamics are the Josephson junctions that connect each island to the ground. We show that QRC implemented in this circuit can accurately classify complex probability distributions, including those with heavy tails, and identify regimes in correlated time series, such as periods of high volatility generated by standard econometric models. We find QRC to outperform some of the best classical methods when the amount of information is limited. This demonstrates its potential to be a noise-resilient quantum learning approach capable of tackling real-world problems within currently available superconducting platforms. We further discuss how to improve our QRC algorithm in real superconducting hardware to benefit from a much larger Hilbert space.

### Molecular Design beyond Training Data with Novel Extended Objective Functionals of Generative AI Models Driven by Quantum Annealing Computer
* **Authors:** Hayato Kunugi et al.
* **Published (v1):** 2026-02-17
* **Updated:** 2026-02-17
* **Link:** http://arxiv.org/abs/2602.15451v1
* **Abstract:** Deep generative modeling to stochastically design small molecules is an emerging technology for accelerating drug discovery and development. However, one major issue in molecular generative models is their lower frequency of drug-like compounds. To resolve this problem, we developed a novel framework for optimization of deep generative models integrated with a D-Wave quantum annealing computer, where our Neural Hash Function (NHF) presented herein is used both as the regularization and binarization schemes simultaneously, of which the latter is for transformation between continuous and discrete signals of the classical and quantum neural networks, respectively, in the error evaluation (i.e., objective) function. The compounds generated via the quantum-annealing generative models exhibited higher quality in both validity and drug-likeness than those generated via the fully-classical models, and was further indicated to exceed even the training data in terms of drug-likeness features, without any restraints and conditions to deliberately induce such an optimization. These results indicated an advantage of quantum annealing to aim at a stochastic generator integrated with our novel neural network architectures, for the extended performance of feature space sampling and extraction of characteristic features in drug design.

### Do we have a quantum computer? Expert perspectives on current status and future prospects
* **Authors:** Liam Doyle et al.
* **Published (v1):** 2026-02-16
* **Updated:** 2026-02-16
* **Link:** http://arxiv.org/abs/2602.15217v1
* **Abstract:** The rapid growth of quantum information science and technology (QIST) in the 21st century has created both excitement and uncertainty about the field's trajectory. This qualitative study presents perspectives from leading quantum researchers, who are educators, on fundamental questions frequently posed by students, the public, and the media regarding QIST. Through in-depth interviews, we explored several issues related to QIST including the following key areas: the current state of quantum computing in the noisy intermediate-scale quantum (NISQ) era and timelines for fault-tolerant quantum computers, the feasibility of personal quantum computers in our pockets, and promising qubit architectures for future development. Our findings reveal diverse yet convergent perspectives on these issues. While experts agree that the current machines with physical qubits that are being built currently should be called quantum computers, most estimated that it will take a decade to build a small fault-tolerant quantum computer, and several decades to achieve scalable systems capable of running Shor's factoring algorithm with quantum advantage. Regarding carrying a quantum computer in the pocket, experts viewed quantum computers as specialized tools that will remain in central locations such as data centers and can be accessed remotely for applications for which they are particularly effective compared to classical computers. Quantum researchers suggested that multiple platforms show promise, with no clear winner emerging. These insights provide valuable guidance for educators, policymakers, and the broader community in establishing realistic expectations for developments in this exciting field. Our findings can provide valuable information for educators to clarify student doubts about these important yet confusing issues related to quantum technologies.

### Permanents of matrix ensembles: computation, distribution, and geometry
* **Authors:** Igor Rivin et al.
* **Published (v1):** 2026-02-08
* **Updated:** 2026-02-16
* **Link:** http://arxiv.org/abs/2602.10141v3
* **Abstract:** We report on a computational and experimental study of permanents. On the computational side, we use the GPU to greaatly accelerate the computation of permanents over $\mathbb{C},$ $\mathbb{R},$ $\mathbb{F}_p$ and $\mathbb{Q}.$ First, for Haar-distributed unitary matrices~$U$, the permanent $\perm(U)$ follows a circularly-symmetric complex Gaussian distribution $\mathcal{CN}(0,σ^2)$ -- we confirm this via a number of tests for $n$ up to~23 with $50{,}000$ samples. The DFT matrix permanent is an extreme outlier for every prime $n\ge 7$. In contrast, for Haar-random \emph{orthogonal} matrices~$O$, the permanent $\perm(O)$ is approximately real Gaussian but with positive excess kurtosis that decays as~$O(1/n)$, indicating slower convergence. For matrices with Gaussian entries (GUE, GOE, Ginibre), the permanent follows an $α$-stable distribution with stability index $α\approx 1.0$--$1.4$, well below the Gaussian value $α=2$. We test Aaronson's conjecture that $|\perm(X)|^2$ is asymptotically lognormal for Gaussian~$X$: it is plausible for the complex Ginibre and GOE ensembles, but appears to fail for GUE and real Ginibre, where the $α$-stable tails prevent convergence. Anti-concentration, however, holds for all Gaussian ensembles and is more robust than for Haar unitaries.   Secondly, we study the permanent along geodesics on the unitary group. For the geodesic from the identity to the $n$-cycle permutation matrix, we find a universal scaling function $f(t)=\frac{1}{n}\ln|\perm(γ(t))|$ that is independent of~$n$ in the large-$n$ limit, with a midpoint value \[   \perm(γ({\textstyle\frac12}))   = (-1)^{(n-1)/2}\cdot 2e^{-n}\bigl(1+\tfrac{1}{3n}+O(n^{-2})\bigr) \] for odd~$n$ and zero for even~$n$. We also study the geodesic forom the identity to the DFT matrix.

### Kernel-based optimization of measurement operators for quantum reservoir computers
* **Authors:** Markus Gross et al.
* **Published (v1):** 2026-02-16
* **Updated:** 2026-02-16
* **Link:** http://arxiv.org/abs/2602.14677v1
* **Abstract:** Finding optimal measurement operators is crucial for the performance of quantum reservoir computers (QRCs), since they employ a fixed quantum feature map. We formulate the training of both stateless (quantum extreme learning machines, QELMs) and stateful (memory dependent) QRCs in the framework of kernel ridge regression. This approach renders an optimal measurement operator that minimizes prediction error for a given reservoir and training dataset. For large qubit numbers, this method is more efficient than the conventional training of QRCs. We discuss efficiency and practical implementation strategies, including Pauli basis decomposition and operator diagonalization, to adapt the optimal observable to hardware constraints. Numerical experiments on image classification and time series prediction tasks demonstrate the effectiveness of this approach, which can also be applied to other quantum ML models.

### Quantum Reservoir Computing with Neutral Atoms on a Small, Complex, Medical Dataset
* **Authors:** Luke Antoncich et al.
* **Published (v1):** 2026-02-16
* **Updated:** 2026-02-16
* **Link:** http://arxiv.org/abs/2602.14641v1
* **Abstract:** Biomarker-based prediction of clinical outcomes is challenging due to nonlinear relationships, correlated features, and the limited size of many medical datasets. Classical machine-learning methods can struggle under these conditions, motivating the search for alternatives. In this work, we investigate quantum reservoir computing (QRC), using both noiseless emulation and hardware execution on the neutral-atom Rydberg processor \textit{Aquila}. We evaluate performance with six classical machine-learning models and use SHAP to generate feature subsets. We find that models trained on emulated quantum features achieve mean test accuracies comparable to those trained on classical features, but have higher training accuracies and greater variability over data splits, consistent with overfitting. When comparing hardware execution of QRC to noiseless emulation, the models are more robust over different data splits and often exhibit statistically significant improvements in mean test accuracy. This combination of improved accuracy and increased stability is suggestive of a regularising effect induced by hardware execution. To investigate the origin of this behaviour, we examine the statistical differences between hardware and emulated quantum feature distributions. We find that hardware execution applies a structured, time-dependent transformation characterised by compression toward the mean and a progressive reduction in mutual information relative to emulation.

### Reverse N-Wise Output-Oriented Testing for AI/ML and Quantum Computing Systems
* **Authors:** Lamine Rihani et al.
* **Published (v1):** 2026-02-15
* **Updated:** 2026-02-15
* **Link:** http://arxiv.org/abs/2602.14275v1
* **Abstract:** Artificial intelligence/machine learning (AI/ML) systems and emerging quantum computing software present unprecedented testing challenges characterized by high-dimensional/continuous input spaces, probabilistic/non-deterministic output distributions, behavioral correctness defined exclusively over observable prediction behaviors and measurement outcomes, and critical quality dimensions, trustworthiness, fairness, calibration, robustness, error syndrome patterns, that manifest through complex multi-way interactions among semantically meaningful output properties rather than deterministic input-output mappings. This paper introduces reverse n-wise output testing, a mathematically principled paradigm inversion that constructs covering arrays directly over domain-specific output equivalence classes, ML confidence calibration buckets, decision boundary regions, fairness partitions, embedding clusters, ranking stability bands, quantum measurement outcome distributions (0-dominant, 1-dominant, superposition collapse), error syndrome patterns (bit-flip, phase-flip, correlated errors), then solves the computationally challenging black-box inverse mapping problem via gradient-free metaheuristic optimization to synthesize input feature configurations or quantum circuit parameters capable of eliciting targeted behavioral signatures from opaque models. The framework delivers synergistic benefits across both domains: explicit customer-centric prediction/measurement coverage guarantees, substantial improvements in fault detection rates for ML calibration/boundary failures and quantum error syndromes, enhanced test suite efficiency, and structured MLOps/quantum validation pipelines with automated partition discovery from uncertainty analysis and coverage drift monitoring.

### Towards a Hybrid Quantum-Classical Computing Framework for Database Optimization Problems in Real Time Setup
* **Authors:** Hanwen Liu et al.
* **Published (v1):** 2026-02-15
* **Updated:** 2026-02-15
* **Link:** http://arxiv.org/abs/2602.14263v1
* **Abstract:** Quantum computing has shown promise for solving complex optimization problems in databases, such as join ordering and index selection. Prior work often submits formulated problems directly to black-box quantum or quantum-inspired solvers with the expectation of directly obtaining a good final solution. Due to the black-box nature of these solvers, users cannot perform fine-grained control over the solving procedure to balance the accuracy and efficiency, which in turn limits flexibility in real-time settings where most database problems arise. Moreover, it leads to limited potential for handling large-scale database optimization problems. In this paper, we propose a vision for the first real-time quantum-augmented database system, enabling transparent solutions for database optimization problems. We develop two complementary scalability strategies to address large-scale challenges, overcomplexity, and oversizing that exceed hardware limits. We integrate our approach with a database query optimizer as a preliminary prototype, evaluating on real-world workload, achieving up to 14x improvement over the classical query optimizer. We also achieve both better efficiency and solution quality than a black-box quantum solver.

### TensorCircuit-NG: A Universal, Composable, and Scalable Platform for Quantum Computing and Quantum Simulation
* **Authors:** Shi-Xin Zhang et al.
* **Published (v1):** 2026-02-15
* **Updated:** 2026-02-15
* **Link:** http://arxiv.org/abs/2602.14167v1
* **Abstract:** We present TensorCircuit-NG, a next-generation quantum software platform designed to bridge the gap between quantum physics, artificial intelligence, and high-performance computing. Moving beyond the scope of traditional circuit simulators, TensorCircuit-NG establishes a unified, tensor-native programming paradigm where quantum circuits, tensor networks, and neural networks fuse into a single, end-to-end differentiable computational graph. Built upon industry-standard machine learning backends (JAX, TensorFlow, PyTorch), the framework introduces comprehensive capabilities for approximate circuit simulation, analog dynamics, fermion Gaussian states, qudit systems, and scalable noise modeling. To tackle the exponential complexity of deep quantum circuits, TensorCircuit-NG implements advanced distributed computing strategies, including automated data parallelism and model-parallel tensor network slicing. We validate these capabilities on GPU clusters, demonstrating a near-linear speedup in distributed variational quantum algorithms. TensorCircuit-NG enables flagship applications, including end-to-end QML for CIFAR-100 computer vision, efficient pipelines from quantum states to neural networks via classical shadows, and differentiable optimization of tensor network states for many-body physics.

### Quantum computation and quantum error correction: the theoretical minimum
* **Authors:** Mark Wildon et al.
* **Published (v1):** 2026-02-14
* **Updated:** 2026-02-14
* **Link:** http://arxiv.org/abs/2602.13876v1
* **Abstract:** These notes introduce quantum computation and quantum error correction, emphasising the importance of stabilisers and the mathematical foundations in basic Lie theory. We begin by using the double cover map $\mathrm{SU}_2 \rightarrow \mathrm{SO}_3(\mathbb{R})$ to illustrate the distinction between states and measurements for a single qubit. We then discuss entanglement and CNOT gates, the Deutsch--Jozsa Problem, and finally quantum error correction, using the Steane $[[7,1,3]]$-code as the main example. The necessary background physics of unitary evolution and Born rule measurements is developed as needed. The circuit model is used throughout.



# Papers Found on: 2026-02-19

### Illustration of Barren Plateaus in Quantum Computing
* **Authors:** Gerhard Stenzel et al.
* **Published (v1):** 2026-02-18
* **Updated:** 2026-02-18
* **Link:** http://arxiv.org/abs/2602.16558v1
* **Abstract:** Variational Quantum Circuits (VQCs) have emerged as a promising paradigm for quantum machine learning in the NISQ era. While parameter sharing in VQCs can reduce the parameter space dimensionality and potentially mitigate the barren plateau phenomenon, it introduces a complex trade-off that has been largely overlooked. This paper investigates how parameter sharing, despite creating better global optima with fewer parameters, fundamentally alters the optimization landscape through deceptive gradients -- regions where gradient information exists but systematically misleads optimizers away from global optima. Through systematic experimental analysis, we demonstrate that increasing degrees of parameter sharing generate more complex solution landscapes with heightened gradient magnitudes and measurably higher deceptiveness ratios. Our findings reveal that traditional gradient-based optimizers (Adam, SGD) show progressively degraded convergence as parameter sharing increases, with performance heavily dependent on hyperparameter selection. We introduce a novel gradient deceptiveness detection algorithm and a quantitative framework for measuring optimization difficulty in quantum circuits, establishing that while parameter sharing can improve circuit expressivity by orders of magnitude, this comes at the cost of significantly increased landscape deceptiveness. These insights provide important considerations for quantum circuit design in practical applications, highlighting the fundamental mismatch between classical optimization strategies and quantum parameter landscapes shaped by parameter sharing.

### MerLean: An Agentic Framework for Autoformalization in Quantum Computation
* **Authors:** Yuanjie Ren et al.
* **Published (v1):** 2026-02-18
* **Updated:** 2026-02-18
* **Link:** http://arxiv.org/abs/2602.16554v1
* **Abstract:** We introduce MerLean, a fully automated agentic framework for autoformalization in quantum computation. MerLean extracts mathematical statements from \LaTeX{} source files, formalizes them into verified Lean~4 code built on Mathlib, and translates the result back into human-readable \LaTeX{} for semantic review. We evaluate MerLean on three theoretical quantum computing papers producing 2,050 Lean declarations from 114 statements in total. MerLean achieves end-to-end formalization on all three papers, reducing the verification burden to only the newly introduced definitions and axioms. Our results demonstrate that agentic autoformalization can scale to frontier research, offering both a practical tool for machine-verified peer review and a scalable engine for mining high-quality synthetic data to train future reasoning models. Our approach can also be generalized to any other rigorous research in mathematics and theoretical physics.

### Computation of thermal conductivity based on Path Integral Monte Carlo methods
* **Authors:** Vladislav Efremkin et al.
* **Published (v1):** 2026-02-18
* **Updated:** 2026-02-18
* **Link:** http://arxiv.org/abs/2602.16405v1
* **Abstract:** The calculation of thermal conductivity in insulating solids at temperatures below the Debye temperature is problematic, due to the breakdown of classical and semi-classical approaches. In this work, we present a fully quantum methodology to compute thermal conductivity based on Path Integral Monte Carlo (PIMC) simulations combined with the Green-Kubo linear response theory. The method is applied to crystalline argon modeled by a Lennard-Jones potential, a paradigmatic system where quantum effects strongly affect both thermodynamic and transport properties. From PIMC simulations, we obtain the temperature-dependent phonon frequencies, lifetimes, and specific heat. From the imaginary time correlations of the energy current, we extract the thermal transport coefficients based on a physically motivated prior. We show that the experimentally observed increase of the thermal conductivity at low temperatures cannot be explained within a standard Peierls-Boltzmann framework or quasi-harmonic approximation using phonon lifetimes alone. Instead, a distinct transport lifetime emerges from the analysis of heat-current correlations. Our results demonstrate that quantum Monte Carlo methods provide a robust, non-perturbative framework to investigate heat transport in insulating solids, beyond the limits of classical molecular dynamics and quasi-harmonic approximations.

### Why the Casimir Force for Magnetic Metals Computed by the Lifshitz Theory Using the Drude Model Disagrees with the Measurement Data
* **Authors:** G. L. Klimchitskaya et al.
* **Published (v1):** 2026-02-18
* **Updated:** 2026-02-18
* **Link:** http://arxiv.org/abs/2602.16370v1
* **Abstract:** We consider the Casimir force in configurations with magnetic metal plates and analyze the reasons why the predictions of the Lifshitz theory using the dielectric permittivity of the Drude model are inconsistent with the measurement data. For this purpose, the contributions of the electromagnetic waves with the transverse magnetic and transverse electric polarizations to the Casimir force are computed using the Lifshitz theory expressed in terms of the pure imaginary Matsubara frequencies. Furthermore, the fractions of the evanescent and propagating waves in these contributions are found using an equivalent formulation of the Lifshitz theory along the real frequency axis. All computations are performed for Au-Ni and Ni-Ni plates using the Drude model and the experimentally consistent plasma model over the separation region from 0.5 to 6~mum, where the total force value is determined by conduction electrons. It is shown that the transverse magnetic contribution to the Casimir force does not depend on the used model of the dielectric permittivity, so that the total difference between the predictions of the Lifshitz theory using the Drude model and the measurement data is determined by the transverse electric contribution. In doing so, as opposed to the case of nonmagnetic metals, both fractions of the evanescent and propagating waves in this contribution depend on the model of the dielectric permittivity used in computations, whereas the magnetic properties of the plate metal influence the Casimir force solely through the fraction of propagating waves in the transverse electric contribution. The issue of a more adequate theoretical description of the electromagnetic response of magnetic metals is discussed.

### Magnetic resonance in quantum computing and in accurate measurements of the nuclear moments of atoms and molecules
* **Authors:** Zhichen Liu et al.
* **Published (v1):** 2026-02-11
* **Updated:** 2026-02-17
* **Link:** http://arxiv.org/abs/2602.11233v2
* **Abstract:** Modern experimental techniques can generate magnetic fields of the form H(t) = H0 z-hat + H1 [x-hat cos(ωt) + y-hat sin(ωt)], at frequencies within an order of magnitude of the nuclear magnetic resonance (NMR) and electron paramagnetic resonance (EPR) frequencies, ωn0 and ωe0, respectively, when acting on atoms or molecules. We derive simple closed-form expressions for the exact nuclear- and electronic-spin wave functions that enable controlled transitions between entangled states, allowing an atom or molecule to function as a quantum computer. These solutions also enable precise NMR or EPR measurements of nuclear moments in atoms and molecules. We present examples relevant to measurements of the nuclear moments of 14N, 7Li, and 133Cs. Because existing hyperfine measurements of the lowest three nuclear moments of 133Cs are mutually inconsistent, the proposed NMR/EPR experiments provide a route to measuring all seven of its nuclear moments with high precision.

### Drone delivery packing problem on a neutral-atom quantum computer
* **Authors:** Sara Tarquini et al.
* **Published (v1):** 2026-02-17
* **Updated:** 2026-02-17
* **Link:** http://arxiv.org/abs/2602.15487v1
* **Abstract:** Quantum architectures based on neutral atoms have gained significant attention in recent years as specialized computational machines due to their ability to directly encode the independent set constraint on graphs, exploiting the Rydberg blockade mechanism. In this work, we address the Drone Delivery Packing Problem via a hybrid quantum-classical framework leveraging a neutral-atom quantum processing unit (QPU). We reformulate the optimization task as a graph-partitioning problem based on the independent sets (ISs) of a scheduling graph that encodes delivery incompatibilities. Each partition corresponds to deliveries assigned to a single drone, with the objective of minimizing the total number of partitions. While the ISs represent time-feasible schedules, battery-duration constraints are enforced through a classical post-processing routine. This methodology enables the recovery of optimal delivery schedules, provided a sufficient number of samples is collected from the QPU to resolve the solution space. We benchmark the hybrid workflow through numerical emulations and demonstrate its effectiveness on Pasqal's Fresnel QPU, reporting hardware experiments with configurations of up to 100 atoms.

### Quantum Computing for Healthcare Digital Twin Systems
* **Authors:** Asma Taheri Monfared et al.
* **Published (v1):** 2026-02-17
* **Updated:** 2026-02-17
* **Link:** http://arxiv.org/abs/2602.15477v1
* **Abstract:** The growing complexity of healthcare systems requires advanced computational models for real-time monitoring, secure data exchange, and intelligent decision-making. Digital Twins (DTs) provide virtual representations of physical healthcare entities, enabling continuous patient monitoring and personalized care. However, classical DT frameworks face limitations in scalability, computational efficiency, and security. Recent studies have introduced Quantum Digital Twins (QDTs) to enhance performance through quantum computing, addressing challenges such as quantum-resistant security and efficient task offloading in healthcare environments. Despite these advances, most existing QDT models remain constrained by fundamental challenges related to quantum hardware limitations, hybrid classical-quantum system integration, cloud-based quantum access, scalability, and clinical trust. This paper provides a comprehensive review of QDTs for healthcare, with a particular focus on identifying and analyzing the key challenges that currently hinder their real-world adoption. Furthermore, it outlines critical research directions and enabling strategies aimed at advancing the development of secure, reliable, and clinically viable quantum digital twin systems for next-generation healthcare applications.

### Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit
* **Authors:** J. J. Prieto-Garcia et al.
* **Published (v1):** 2026-02-17
* **Updated:** 2026-02-17
* **Link:** http://arxiv.org/abs/2602.15474v1
* **Abstract:** We analyze numerically the performance of Quantum Reservoir Computing (QRC) for statistical and financial problems. We use a reservoir composed of two superconducting islands coupled via their charge degrees of freedom. The key non-linear elements that provide the reservoir with rich and complex dynamics are the Josephson junctions that connect each island to the ground. We show that QRC implemented in this circuit can accurately classify complex probability distributions, including those with heavy tails, and identify regimes in correlated time series, such as periods of high volatility generated by standard econometric models. We find QRC to outperform some of the best classical methods when the amount of information is limited. This demonstrates its potential to be a noise-resilient quantum learning approach capable of tackling real-world problems within currently available superconducting platforms. We further discuss how to improve our QRC algorithm in real superconducting hardware to benefit from a much larger Hilbert space.

### Molecular Design beyond Training Data with Novel Extended Objective Functionals of Generative AI Models Driven by Quantum Annealing Computer
* **Authors:** Hayato Kunugi et al.
* **Published (v1):** 2026-02-17
* **Updated:** 2026-02-17
* **Link:** http://arxiv.org/abs/2602.15451v1
* **Abstract:** Deep generative modeling to stochastically design small molecules is an emerging technology for accelerating drug discovery and development. However, one major issue in molecular generative models is their lower frequency of drug-like compounds. To resolve this problem, we developed a novel framework for optimization of deep generative models integrated with a D-Wave quantum annealing computer, where our Neural Hash Function (NHF) presented herein is used both as the regularization and binarization schemes simultaneously, of which the latter is for transformation between continuous and discrete signals of the classical and quantum neural networks, respectively, in the error evaluation (i.e., objective) function. The compounds generated via the quantum-annealing generative models exhibited higher quality in both validity and drug-likeness than those generated via the fully-classical models, and was further indicated to exceed even the training data in terms of drug-likeness features, without any restraints and conditions to deliberately induce such an optimization. These results indicated an advantage of quantum annealing to aim at a stochastic generator integrated with our novel neural network architectures, for the extended performance of feature space sampling and extraction of characteristic features in drug design.

### Do we have a quantum computer? Expert perspectives on current status and future prospects
* **Authors:** Liam Doyle et al.
* **Published (v1):** 2026-02-16
* **Updated:** 2026-02-16
* **Link:** http://arxiv.org/abs/2602.15217v1
* **Abstract:** The rapid growth of quantum information science and technology (QIST) in the 21st century has created both excitement and uncertainty about the field's trajectory. This qualitative study presents perspectives from leading quantum researchers, who are educators, on fundamental questions frequently posed by students, the public, and the media regarding QIST. Through in-depth interviews, we explored several issues related to QIST including the following key areas: the current state of quantum computing in the noisy intermediate-scale quantum (NISQ) era and timelines for fault-tolerant quantum computers, the feasibility of personal quantum computers in our pockets, and promising qubit architectures for future development. Our findings reveal diverse yet convergent perspectives on these issues. While experts agree that the current machines with physical qubits that are being built currently should be called quantum computers, most estimated that it will take a decade to build a small fault-tolerant quantum computer, and several decades to achieve scalable systems capable of running Shor's factoring algorithm with quantum advantage. Regarding carrying a quantum computer in the pocket, experts viewed quantum computers as specialized tools that will remain in central locations such as data centers and can be accessed remotely for applications for which they are particularly effective compared to classical computers. Quantum researchers suggested that multiple platforms show promise, with no clear winner emerging. These insights provide valuable guidance for educators, policymakers, and the broader community in establishing realistic expectations for developments in this exciting field. Our findings can provide valuable information for educators to clarify student doubts about these important yet confusing issues related to quantum technologies.

### Permanents of matrix ensembles: computation, distribution, and geometry
* **Authors:** Igor Rivin et al.
* **Published (v1):** 2026-02-08
* **Updated:** 2026-02-16
* **Link:** http://arxiv.org/abs/2602.10141v3
* **Abstract:** We report on a computational and experimental study of permanents. On the computational side, we use the GPU to greaatly accelerate the computation of permanents over $\mathbb{C},$ $\mathbb{R},$ $\mathbb{F}_p$ and $\mathbb{Q}.$ First, for Haar-distributed unitary matrices~$U$, the permanent $\perm(U)$ follows a circularly-symmetric complex Gaussian distribution $\mathcal{CN}(0,σ^2)$ -- we confirm this via a number of tests for $n$ up to~23 with $50{,}000$ samples. The DFT matrix permanent is an extreme outlier for every prime $n\ge 7$. In contrast, for Haar-random \emph{orthogonal} matrices~$O$, the permanent $\perm(O)$ is approximately real Gaussian but with positive excess kurtosis that decays as~$O(1/n)$, indicating slower convergence. For matrices with Gaussian entries (GUE, GOE, Ginibre), the permanent follows an $α$-stable distribution with stability index $α\approx 1.0$--$1.4$, well below the Gaussian value $α=2$. We test Aaronson's conjecture that $|\perm(X)|^2$ is asymptotically lognormal for Gaussian~$X$: it is plausible for the complex Ginibre and GOE ensembles, but appears to fail for GUE and real Ginibre, where the $α$-stable tails prevent convergence. Anti-concentration, however, holds for all Gaussian ensembles and is more robust than for Haar unitaries.   Secondly, we study the permanent along geodesics on the unitary group. For the geodesic from the identity to the $n$-cycle permutation matrix, we find a universal scaling function $f(t)=\frac{1}{n}\ln|\perm(γ(t))|$ that is independent of~$n$ in the large-$n$ limit, with a midpoint value \[   \perm(γ({\textstyle\frac12}))   = (-1)^{(n-1)/2}\cdot 2e^{-n}\bigl(1+\tfrac{1}{3n}+O(n^{-2})\bigr) \] for odd~$n$ and zero for even~$n$. We also study the geodesic forom the identity to the DFT matrix.

### Kernel-based optimization of measurement operators for quantum reservoir computers
* **Authors:** Markus Gross et al.
* **Published (v1):** 2026-02-16
* **Updated:** 2026-02-16
* **Link:** http://arxiv.org/abs/2602.14677v1
* **Abstract:** Finding optimal measurement operators is crucial for the performance of quantum reservoir computers (QRCs), since they employ a fixed quantum feature map. We formulate the training of both stateless (quantum extreme learning machines, QELMs) and stateful (memory dependent) QRCs in the framework of kernel ridge regression. This approach renders an optimal measurement operator that minimizes prediction error for a given reservoir and training dataset. For large qubit numbers, this method is more efficient than the conventional training of QRCs. We discuss efficiency and practical implementation strategies, including Pauli basis decomposition and operator diagonalization, to adapt the optimal observable to hardware constraints. Numerical experiments on image classification and time series prediction tasks demonstrate the effectiveness of this approach, which can also be applied to other quantum ML models.

### Quantum Reservoir Computing with Neutral Atoms on a Small, Complex, Medical Dataset
* **Authors:** Luke Antoncich et al.
* **Published (v1):** 2026-02-16
* **Updated:** 2026-02-16
* **Link:** http://arxiv.org/abs/2602.14641v1
* **Abstract:** Biomarker-based prediction of clinical outcomes is challenging due to nonlinear relationships, correlated features, and the limited size of many medical datasets. Classical machine-learning methods can struggle under these conditions, motivating the search for alternatives. In this work, we investigate quantum reservoir computing (QRC), using both noiseless emulation and hardware execution on the neutral-atom Rydberg processor \textit{Aquila}. We evaluate performance with six classical machine-learning models and use SHAP to generate feature subsets. We find that models trained on emulated quantum features achieve mean test accuracies comparable to those trained on classical features, but have higher training accuracies and greater variability over data splits, consistent with overfitting. When comparing hardware execution of QRC to noiseless emulation, the models are more robust over different data splits and often exhibit statistically significant improvements in mean test accuracy. This combination of improved accuracy and increased stability is suggestive of a regularising effect induced by hardware execution. To investigate the origin of this behaviour, we examine the statistical differences between hardware and emulated quantum feature distributions. We find that hardware execution applies a structured, time-dependent transformation characterised by compression toward the mean and a progressive reduction in mutual information relative to emulation.

### Reverse N-Wise Output-Oriented Testing for AI/ML and Quantum Computing Systems
* **Authors:** Lamine Rihani et al.
* **Published (v1):** 2026-02-15
* **Updated:** 2026-02-15
* **Link:** http://arxiv.org/abs/2602.14275v1
* **Abstract:** Artificial intelligence/machine learning (AI/ML) systems and emerging quantum computing software present unprecedented testing challenges characterized by high-dimensional/continuous input spaces, probabilistic/non-deterministic output distributions, behavioral correctness defined exclusively over observable prediction behaviors and measurement outcomes, and critical quality dimensions, trustworthiness, fairness, calibration, robustness, error syndrome patterns, that manifest through complex multi-way interactions among semantically meaningful output properties rather than deterministic input-output mappings. This paper introduces reverse n-wise output testing, a mathematically principled paradigm inversion that constructs covering arrays directly over domain-specific output equivalence classes, ML confidence calibration buckets, decision boundary regions, fairness partitions, embedding clusters, ranking stability bands, quantum measurement outcome distributions (0-dominant, 1-dominant, superposition collapse), error syndrome patterns (bit-flip, phase-flip, correlated errors), then solves the computationally challenging black-box inverse mapping problem via gradient-free metaheuristic optimization to synthesize input feature configurations or quantum circuit parameters capable of eliciting targeted behavioral signatures from opaque models. The framework delivers synergistic benefits across both domains: explicit customer-centric prediction/measurement coverage guarantees, substantial improvements in fault detection rates for ML calibration/boundary failures and quantum error syndromes, enhanced test suite efficiency, and structured MLOps/quantum validation pipelines with automated partition discovery from uncertainty analysis and coverage drift monitoring.

### Towards a Hybrid Quantum-Classical Computing Framework for Database Optimization Problems in Real Time Setup
* **Authors:** Hanwen Liu et al.
* **Published (v1):** 2026-02-15
* **Updated:** 2026-02-15
* **Link:** http://arxiv.org/abs/2602.14263v1
* **Abstract:** Quantum computing has shown promise for solving complex optimization problems in databases, such as join ordering and index selection. Prior work often submits formulated problems directly to black-box quantum or quantum-inspired solvers with the expectation of directly obtaining a good final solution. Due to the black-box nature of these solvers, users cannot perform fine-grained control over the solving procedure to balance the accuracy and efficiency, which in turn limits flexibility in real-time settings where most database problems arise. Moreover, it leads to limited potential for handling large-scale database optimization problems. In this paper, we propose a vision for the first real-time quantum-augmented database system, enabling transparent solutions for database optimization problems. We develop two complementary scalability strategies to address large-scale challenges, overcomplexity, and oversizing that exceed hardware limits. We integrate our approach with a database query optimizer as a preliminary prototype, evaluating on real-world workload, achieving up to 14x improvement over the classical query optimizer. We also achieve both better efficiency and solution quality than a black-box quantum solver.

### TensorCircuit-NG: A Universal, Composable, and Scalable Platform for Quantum Computing and Quantum Simulation
* **Authors:** Shi-Xin Zhang et al.
* **Published (v1):** 2026-02-15
* **Updated:** 2026-02-15
* **Link:** http://arxiv.org/abs/2602.14167v1
* **Abstract:** We present TensorCircuit-NG, a next-generation quantum software platform designed to bridge the gap between quantum physics, artificial intelligence, and high-performance computing. Moving beyond the scope of traditional circuit simulators, TensorCircuit-NG establishes a unified, tensor-native programming paradigm where quantum circuits, tensor networks, and neural networks fuse into a single, end-to-end differentiable computational graph. Built upon industry-standard machine learning backends (JAX, TensorFlow, PyTorch), the framework introduces comprehensive capabilities for approximate circuit simulation, analog dynamics, fermion Gaussian states, qudit systems, and scalable noise modeling. To tackle the exponential complexity of deep quantum circuits, TensorCircuit-NG implements advanced distributed computing strategies, including automated data parallelism and model-parallel tensor network slicing. We validate these capabilities on GPU clusters, demonstrating a near-linear speedup in distributed variational quantum algorithms. TensorCircuit-NG enables flagship applications, including end-to-end QML for CIFAR-100 computer vision, efficient pipelines from quantum states to neural networks via classical shadows, and differentiable optimization of tensor network states for many-body physics.

### Quantum computation and quantum error correction: the theoretical minimum
* **Authors:** Mark Wildon et al.
* **Published (v1):** 2026-02-14
* **Updated:** 2026-02-14
* **Link:** http://arxiv.org/abs/2602.13876v1
* **Abstract:** These notes introduce quantum computation and quantum error correction, emphasising the importance of stabilisers and the mathematical foundations in basic Lie theory. We begin by using the double cover map $\mathrm{SU}_2 \rightarrow \mathrm{SO}_3(\mathbb{R})$ to illustrate the distinction between states and measurements for a single qubit. We then discuss entanglement and CNOT gates, the Deutsch--Jozsa Problem, and finally quantum error correction, using the Steane $[[7,1,3]]$-code as the main example. The necessary background physics of unitary evolution and Born rule measurements is developed as needed. The circuit model is used throughout.

