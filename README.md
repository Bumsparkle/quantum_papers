

# Papers Found on: 2026-02-24

### Reversible Information Transformation via Quantum Reservoir Computing: Conditions, Protocol, and Noise Resilience
* **Authors:** Hikaru Wakaura et al.
* **Published (v1):** 2026-02-23
* **Updated:** 2026-02-23
* **Link:** http://arxiv.org/abs/2602.19700v1
* **Abstract:** Quantum reservoir computing (QRC) exploits fixed quantum dynamics and a trainable linear readout to process temporal data, yet reversing the transformation -- reconstructing the input from the reservoir output -- has been considered intractable owing to the recursive nonlinearity of sequential quantum state evolution. Here we propose a four-equation encode-decode protocol with cross-key pairing and constructively show that quantum reservoir and key combinations satisfying all four equations exist. Using a full XYZ Hamiltonian reservoir with 10 data qubits, we expand the feature dimension to 76 without increasing qubit count and achieve machine-precision reconstruction (mean-squared error $\mathrm{MSE} \sim 10^{-17}$) for data lengths up to 30 under ideal conditions; the rank condition $\mathrm{dim}(V) \geq N_c$ is identified as a necessary criterion. A comprehensive noise analysis across seven conditions and four baseline methods reveals a clear hierarchy: shot noise dominates, depolarizing noise adds a moderate factor, and asymmetric resource allocation -- 10 shots for encoding, $10^5$ for decoding -- yields approximately two orders of magnitude MSE improvement by exploiting the asymmetric noise roles of the encryption and decryption feature matrices. Under realistic noise the MSE degrades to $10^{-3}$-$10^{-1}$, indicating that error mitigation is needed before practical deployment, but our results establish the feasibility of bidirectional reversible information transformation within QRC.

### Kaiwu-PyTorch-Plugin: Bridging Deep Learning and Photonic Quantum Computing for Energy-Based Models and Active Sample Selection
* **Authors:** Hongdong Zhu et al.
* **Published (v1):** 2026-02-22
* **Updated:** 2026-02-22
* **Link:** http://arxiv.org/abs/2602.19114v1
* **Abstract:** This paper introduces the Kaiwu-PyTorch-Plugin (KPP) to bridge Deep Learning and Photonic Quantum Computing across multiple dimensions. KPP integrates the Coherent Ising Machine into the PyTorch ecosystem, addressing classical inefficiencies in Energy-Based Models. The framework facilitates quantum integration in three key aspects: accelerating Boltzmann sampling, optimizing training data via Active Sampling, and constructing hybrid architectures like QBM-VAE and Q-Diffusion. Empirical results on single-cell and OpenWebText datasets demonstrate KPPs ability to achieve SOTA performance, validating a comprehensive quantum-classical paradigm.

### What Distributed Computing Got Wrong: The Category Mistake That Turned Design Choices into Laws of Nature
* **Authors:** Paul Borrill et al.
* **Published (v1):** 2026-02-21
* **Updated:** 2026-02-21
* **Link:** http://arxiv.org/abs/2602.18723v1
* **Abstract:** The foundational impossibility results of distributed computing -- the Fischer-Lynch-Paterson theorem, the Two Generals Problem, the CAP theorem -- are widely understood as discoveries about the physical limits of coordination. This paper argues that they are nothing of the sort. They are consequences of a category mistake: treating Forward-In-Time-Only (FITO) information flow as a law of nature rather than recognizing it as a design choice inherited from Shannon's channel model and Lamport's happened-before relation. We develop this argument in six steps. First, we introduce the category mistake framework from Ryle through Spekkens' ontic/epistemic distinction in quantum foundations. Second, we identify FITO as the hidden axiom that unifies the classical impossibility results. Third, we apply Spekkens' Leibnizian principle to show that FITO-based models contain surplus ontological structure. Fourth, we develop the counterfactual: what changes when FITO is dropped. Fifth, we demonstrate that the impossibility theorems are theorems about FITO systems, not about physics. Sixth, we sketch the transactional alternative -- bilateral interactions that dissolve the apparent impossibilities by replacing unidirectional message passing with atomic bilateral transactions. The implication is that distributed computing has spent fifty years optimizing within the wrong design space.



# Papers Found on: 2026-02-24

### Reversible Information Transformation via Quantum Reservoir Computing: Conditions, Protocol, and Noise Resilience
* **Authors:** Hikaru Wakaura et al.
* **Published (v1):** 2026-02-23
* **Updated:** 2026-02-23
* **Link:** http://arxiv.org/abs/2602.19700v1
* **Abstract:** Quantum reservoir computing (QRC) exploits fixed quantum dynamics and a trainable linear readout to process temporal data, yet reversing the transformation -- reconstructing the input from the reservoir output -- has been considered intractable owing to the recursive nonlinearity of sequential quantum state evolution. Here we propose a four-equation encode-decode protocol with cross-key pairing and constructively show that quantum reservoir and key combinations satisfying all four equations exist. Using a full XYZ Hamiltonian reservoir with 10 data qubits, we expand the feature dimension to 76 without increasing qubit count and achieve machine-precision reconstruction (mean-squared error $\mathrm{MSE} \sim 10^{-17}$) for data lengths up to 30 under ideal conditions; the rank condition $\mathrm{dim}(V) \geq N_c$ is identified as a necessary criterion. A comprehensive noise analysis across seven conditions and four baseline methods reveals a clear hierarchy: shot noise dominates, depolarizing noise adds a moderate factor, and asymmetric resource allocation -- 10 shots for encoding, $10^5$ for decoding -- yields approximately two orders of magnitude MSE improvement by exploiting the asymmetric noise roles of the encryption and decryption feature matrices. Under realistic noise the MSE degrades to $10^{-3}$-$10^{-1}$, indicating that error mitigation is needed before practical deployment, but our results establish the feasibility of bidirectional reversible information transformation within QRC.

### Kaiwu-PyTorch-Plugin: Bridging Deep Learning and Photonic Quantum Computing for Energy-Based Models and Active Sample Selection
* **Authors:** Hongdong Zhu et al.
* **Published (v1):** 2026-02-22
* **Updated:** 2026-02-22
* **Link:** http://arxiv.org/abs/2602.19114v1
* **Abstract:** This paper introduces the Kaiwu-PyTorch-Plugin (KPP) to bridge Deep Learning and Photonic Quantum Computing across multiple dimensions. KPP integrates the Coherent Ising Machine into the PyTorch ecosystem, addressing classical inefficiencies in Energy-Based Models. The framework facilitates quantum integration in three key aspects: accelerating Boltzmann sampling, optimizing training data via Active Sampling, and constructing hybrid architectures like QBM-VAE and Q-Diffusion. Empirical results on single-cell and OpenWebText datasets demonstrate KPPs ability to achieve SOTA performance, validating a comprehensive quantum-classical paradigm.

### What Distributed Computing Got Wrong: The Category Mistake That Turned Design Choices into Laws of Nature
* **Authors:** Paul Borrill et al.
* **Published (v1):** 2026-02-21
* **Updated:** 2026-02-21
* **Link:** http://arxiv.org/abs/2602.18723v1
* **Abstract:** The foundational impossibility results of distributed computing -- the Fischer-Lynch-Paterson theorem, the Two Generals Problem, the CAP theorem -- are widely understood as discoveries about the physical limits of coordination. This paper argues that they are nothing of the sort. They are consequences of a category mistake: treating Forward-In-Time-Only (FITO) information flow as a law of nature rather than recognizing it as a design choice inherited from Shannon's channel model and Lamport's happened-before relation. We develop this argument in six steps. First, we introduce the category mistake framework from Ryle through Spekkens' ontic/epistemic distinction in quantum foundations. Second, we identify FITO as the hidden axiom that unifies the classical impossibility results. Third, we apply Spekkens' Leibnizian principle to show that FITO-based models contain surplus ontological structure. Fourth, we develop the counterfactual: what changes when FITO is dropped. Fifth, we demonstrate that the impossibility theorems are theorems about FITO systems, not about physics. Sixth, we sketch the transactional alternative -- bilateral interactions that dissolve the apparent impossibilities by replacing unidirectional message passing with atomic bilateral transactions. The implication is that distributed computing has spent fifty years optimizing within the wrong design space.

